knitr::opts_chunk$set(echo = TRUE)
library(tm)
library(tidyverse)
library(openNLP)
library(SnowballC)
library(ggthemes)
library(ggrepel)
getwd()
setwd("~/Desktop/CEU_text_as_data/meeting_3/") # this is an example, paste your path here
setwd("~/Desktop/CEU_text_as_data/meeting_3/") # this is an example, paste your path here
getwd()
dir()
federalist <- read_csv("federalist.csv")
federalist
federalist <- read.csv("federalist.csv")
federalist
federalist <- read_csv("federalist.csv")
federalist
names(federalist)
federalist$paper_id
federalist$text[1] # explain this!
add_one <- function(x) {x + 1}
y = 1
add_one(y)
add_one <- function(x) {x + 1}
add_three <- function(x) {x + 3}
step_1 <- add_one(y)
step_1
step_2 <- add_three(step_1)
step_2
add_one(y)
add_three(add_one(y))
y %>% add_one()
y %>% add_one()
y %>% add_one() %>% add_three()
?mutate
federalist$text[1]
?str_to_lower
length(federalist$text)
test_text <- federalist$text[1]
str_split(test_text, " ")
str_split(test_text, " ")[[1]]
length(str_split(test_text, " ")[[1]])
clean_federalist <- federalist %>%
mutate(                           # the mutate() function is part of dplyr package / allows to change stuff within the dataframe easily
text   = str_to_lower(text),                # turn all letters to lowercase
text   = str_replace_all(text, "\n", " "),  # replace '/n' carriage return symbols
text   = str_remove_all(text, "[:punct:]"), # remove all punctuation
man    = str_count(text, "\\Wman "),        # Basic regex (more about it later in the course. '\\W' part means at the begging of the word) and count those up
by     = str_count(text, "\\Wby "),         # same
upon   = str_count(text, "\\Wupon ")        # same
) %>%
rowwise() %>%                                 # make future functions work rowwise
mutate(
length = length(str_split(text, " ")[[1]])  # calculate the length of the text (in words)
)
clean_federalist
clean_federalist$text[1]
clean_federalist %>%
select(man, by, upon)
clean_federalist
clean_federalist %>%
filter(author == "MADISON") %>%
select(man, by, upon)
mu_madison <- clean_federalist %>%
filter(author == "MADISON") %>%
select(man, by, upon) %>%
colSums()
mu_madison
mu_hamilton <- clean_federalist %>%
filter(author == "HAMILTON") %>%
select(man, by, upon) %>%
colSums()
mu_jay <- clean_federalist %>%
filter(author == "JAY") %>%
select(man, by, upon) %>%
colSums()
mu_madison; mu_hamilton; mu_jay
mu_hamilton
sum(mu_hamilton)
mu_hat_hamilton <- mu_hamilton / sum(mu_hamilton)
mu_hat_madison <- mu_madison / sum(mu_madison)
mu_hat_jay <- mu_jay / sum(mu_jay)
mu_hat_hamilton
mu_hat_madison
mu_hat_jay
clean_federalist[49, ]
clean_federalist$author[49]
mu_disputed <- clean_federalist[49, ] %>%
select(man, by, upon)
mu_disputed
?dmultinom
mu_disputed
mu_hat_hamilton
p_disputed_hamilton <- dmultinom(mu_disputed,
prob = mu_hat_hamilton)
p_disputed_madison  <- dmultinom(mu_disputed,
prob = mu_hat_madison)
p_disputed_jay      <- dmultinom(mu_disputed,
prob = mu_hat_jay)
p_disputed_hamilton; p_disputed_madison; p_disputed_jay
mu_madison; mu_hamilton; mu_jay
vector_visualizations <- rbind(mu_madison, mu_hamilton, mu_jay, mu_disputed)
vector_visualizations
mu_madison
vector_visualizations$author = c("Madison", "Hamilton", "Jay", "Disputed")
vector_visualizations
vector_visualizations
vector_visualizations %>% select(-by)
vector_visualizations_no_man <- vector_visualizations %>%
select(-man)
vector_visualizations_no_man
vector_visualizations_no_man %>%
ggplot()
vector_visualizations_no_man %>%
ggplot() +
geom_segment(aes(x = 0, y = 0, xend = by, yend = upon, color = factor(author)),
arrow = arrow(length = unit(0.2,"cm")),
size = 1) +
theme_tufte() +
theme(
# legend.position = "none",
axis.title.x = element_text(size = 18),
axis.title.y = element_text(size = 18),
axis.text.x = element_text(size = 18),
axis.text.y = element_text(size = 18)
) +
xlab("By") +
ylab("Upon") +
labs(color = 'Author')
vector_visualizations_no_by <- vector_visualizations %>%
select(-by)
vector_visualizations_no_by %>%
ggplot() +
geom_segment(aes(x = 0, y = 0, xend = man, yend = upon, color = factor(author)),
arrow = arrow(length = unit(0.2,"cm")),
size = 1) +
theme_tufte() +
theme(
# legend.position = "none",
axis.title.x = element_text(size = 18),
axis.title.y = element_text(size = 18),
axis.text.x = element_text(size = 18),
axis.text.y = element_text(size = 18)
) +
xlab("Man") +
ylab("Upon") +
labs(color = 'Author')
vector_visualizations_no_by[4, 1:2] <- vector_visualizations_no_by[4, 1:2] * 100
vector_visualizations_no_by[3, 1:2] <- vector_visualizations_no_by[3, 1:2] * 100
vector_visualizations_no_by %>%
ggplot() +
geom_segment(aes(x = 0, y = 0, xend = man, yend = upon, color = factor(author)),
arrow = arrow(length = unit(0.2,"cm")),
size = 1) +
theme_tufte() +
theme(
# legend.position = "none",
axis.title.x = element_text(size = 18),
axis.title.y = element_text(size = 18),
axis.text.x = element_text(size = 18),
axis.text.y = element_text(size = 18)
) +
xlab("Man") +
ylab("Upon") +
labs(color = 'Author')
cosine_sim <- function(A, B) {
numerator   <- A %*% B
denominator <- sqrt(sum(A^2)) * sqrt(sum(B^2))
similiarity <- numerator / denominator
return(similiarity)
}
vectors <- vector_visualizations[, 1:3] %>% as.matrix()
vectors
similarity_matrix <- matrix(
nrow = 4, ncol = 4
)
similarity_matrix
for (i in 1:nrow(similarity_matrix)) {
for (j in 1:ncol(similarity_matrix)) {
similarity_matrix[i, j] = cosine_sim(vectors[i, ], vectors[j, ])
}
}
rownames(similarity_matrix) <- vector_visualizations$author
colnames(similarity_matrix) <- vector_visualizations$author
similarity_matrix
library(tm)
library(tidyverse)
library(openNLP)
library(SnowballC)
library(ggthemes)
library(ggrepel)
getwd()
setwd("~/Desktop/CEU_text_as_data/meeting_3/") # this is an example, paste your path here
federalist <- read_csv("federalist.csv")
federalist <- read_csv("federalist.csv")
clean_federalist_all_words <- federalist %>%
mutate(                           # the mutate() function is part of dplyr package / allows to change stuff within the dataframe easily
text   = str_to_lower(text),                # turn all letters to lowercase
text   = str_replace_all(text, "\n", " "),  # replace '/n' carriage return symbols
text   = str_remove_all(text, "[:punct:]") # remove all punctuation
) %>%
rowwise() %>%                                 # make future functions work rowwise
mutate(
length = length(str_split(text, " ")[[1]])  # calculate the length of the text (in words)
)
federalist_dtm <- DocumentTermMatrix(
clean_federalist_all_words$text
)
federalist_dtm
federalist_dtm
federalist_dtm %>% as.matrix()
clean_federalist_all_words
hamilton_idx <- which(clean_federalist_all_words$author == "HAMILTON")
hamilton_idx
